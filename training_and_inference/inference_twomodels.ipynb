{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, keras, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import sys\n",
    "sys.path.append('../input/myfiles/') # for uploaded code on kaggle\n",
    "from unet import Unet\n",
    "\n",
    "modelnamefold1 = '../input/models/efub4_nbr320_tripleloss_combosegdense_fold1.h5'\n",
    "modelnamefold2 = '../input/models/efub4_nbr320_tripleloss_combosegdense_fold2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "SEED=2019\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataGenerator():\n",
    "    def __init__(self ,image_folder, df=None, mean_std = (0., 1.)):\n",
    "        self.df = df\n",
    "        self.image_folder = image_folder\n",
    "        self.mean_std = mean_std\n",
    "        self.use_nbr = 'nonBlackRegion' in df.columns\n",
    "        self.lendf = len(df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.lendf\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        im_name = self.df['ImageId'].iloc[index]\n",
    "        img_path = self.image_folder + im_name\n",
    "        img = self._load_rgb(img_path)\n",
    "        if self.use_nbr is not None:\n",
    "            nbr = self.df['nonBlackRegion'].iloc[index]\n",
    "            img = img[:,nbr[0]:nbr[1],:]\n",
    "        img_tta = np.empty((4, *img.shape))\n",
    "        img_tta[0] = img\n",
    "        for ti, fa in enumerate([0, 1, (0,1)]):\n",
    "            img_tta[ti+1] = np.flip(img, axis=fa)\n",
    "        return img_tta\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def _load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = (img - self.mean_std[0]) / self.mean_std[1]\n",
    "        return img\n",
    "    \n",
    "def mask2rle(img):\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    return rles\n",
    "\n",
    "def findNonBlackRegion(img):\n",
    "    assert len(img.shape) == 2\n",
    "    thd = img < 20\n",
    "    vert = np.int32(np.all(thd, axis=0))\n",
    "    vertshift = vert[:-1] - vert[1:]\n",
    "    if vert[0] == 1: # left side\n",
    "        maxind = img.shape[-1]\n",
    "        minind = np.min(np.where(vertshift==1))\n",
    "        return [minind, maxind], True\n",
    "    elif vert[-1] == 1: # right side\n",
    "        minind = 0\n",
    "        maxind = np.max(np.where(vertshift==-1)) + 1\n",
    "        return [minind, maxind], True\n",
    "    else:\n",
    "        return [0, img.shape[-1]], False\n",
    "    \n",
    "def nonBlackRegion(imgname, folder, roundoff=None):\n",
    "    img = cv2.imread(folder + imgname, 0)\n",
    "    nbr, _ = findNonBlackRegion(img)\n",
    "    if roundoff is not None:\n",
    "        diff = (nbr[0] - nbr[1])\n",
    "        if nbr[0] == 0:\n",
    "            nbr[1] = nbr[1] + (diff % roundoff)\n",
    "        else:\n",
    "            nbr[0] = nbr[0] - (diff % roundoff)\n",
    "#     assert nbr[0] >= 0, \"%s\"%(str(nbr))\n",
    "#     assert nbr[1] <= 1600, \"%s\"%(str(nbr))\n",
    "#     assert (nbr[1] - nbr[0]) % 32 == 0, \"%s\"%(str(nbr))\n",
    "    return nbr\n",
    "\n",
    "def argmax_predictions(predictions):\n",
    "    predflat = np.reshape(predictions, (-1, predictions.shape[-1]))\n",
    "    p_am = np.argmax(predflat, axis=-1)\n",
    "    outs = np.zeros(predflat.shape)\n",
    "    outs[np.arange(p_am.size), p_am] = 1\n",
    "    outs = np.reshape(outs, predictions.shape)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.373556s\n"
     ]
    }
   ],
   "source": [
    "ticstart = time.time()\n",
    "\n",
    "# base_path = '../data/'\n",
    "base_path = '../input/severstal-steel-defect-detection/'\n",
    "images_folder = base_path + 'test_images/'\n",
    "sample_df = pd.read_csv(base_path+'sample_submission.csv')\n",
    "sample_df['ImageId'] = sample_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "nbr_df =  pd.DataFrame(sample_df['ImageId'].unique(), columns=['ImageId'])\n",
    "nbr_df['nonBlackRegion'] = nbr_df['ImageId'].apply(lambda name: nonBlackRegion(name, images_folder, 32))\n",
    "\n",
    "print(\"%fs\" % (time.time() - ticstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_std = (0.39531398, 0.1560004)  # without black regions\n",
    "test_generator = InferenceDataGenerator(image_folder = images_folder, df = nbr_df, mean_std = train_mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.326954s\n"
     ]
    }
   ],
   "source": [
    "ticstart = time.time()\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Conv2D, Concatenate, MaxPooling2D\n",
    "def get_model():\n",
    "    BACKBONE = 'efficientnetb4'\n",
    "    decoder_filters=(256, 128, 128, 64, 64)\n",
    "    decoder_block_type = 'transpose3layer'\n",
    "    auxseg_layername = 'decoder_stage4b2_swish' # changes with activation name\n",
    "    layer_names = {'segmentation': 'masks', \n",
    "                   'classification': 'classifier', \n",
    "                   'auxilliary': 'auxilliary_segmentation'}\n",
    "    effunet = Unet(backbone_name = BACKBONE, input_shape=(None,None,3), \n",
    "                     encoder_weights=None, \n",
    "                     encoder_freeze=False, \n",
    "                     classes=5,\n",
    "                     activation='softmax',\n",
    "                     decoder_filters=decoder_filters,\n",
    "                     output_name=layer_names['segmentation'], \n",
    "                     decoder_activation='swish',\n",
    "                     decoder_block_type = decoder_block_type)\n",
    "    \n",
    "    seghead = effunet.get_layer(auxseg_layername).output\n",
    "    auxseg = Conv2D(filters=5, kernel_size=(3, 3), \n",
    "                    padding='same', use_bias=True,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='glorot_uniform',\n",
    "                    name=layer_names['auxilliary'])(seghead)\n",
    "    \n",
    "    x = MaxPooling2D(32)(auxseg)\n",
    "    poolseg = GlobalAveragePooling2D()(x)\n",
    "    avgseg = GlobalAveragePooling2D()(auxseg)\n",
    "    maxseg = GlobalMaxPooling2D()(auxseg)\n",
    "    x = Concatenate()([maxseg, avgseg, poolseg])\n",
    "    classifier = Dense(4, activation='sigmoid', name=layer_names['classification'])(x)  \n",
    "    \n",
    "    model = Model(inputs=effunet.inputs, outputs=[effunet.output, classifier, auxseg])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "print(\"%fs\" % (time.time() - ticstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(inference_generator, nbr_df, input_df, cls_th, aux_th, use_masks_from_df=False):\n",
    "    tic = time.time()\n",
    "    res_df = []\n",
    "    for gi in range(len(inference_generator)):\n",
    "        tta_img = inference_generator[gi]\n",
    "        modelout_tta = model.predict_on_batch(tta_img)\n",
    "        masks_tta, cls_tta, auxseg_tta = modelout_tta\n",
    "        for ti, fa in enumerate([0, 1, (0,1)]):\n",
    "            masks_tta[ti+1] = np.flip(masks_tta[ti+1], axis=fa)\n",
    "            auxseg_tta[ti+1] = np.flip(auxseg_tta[ti+1], axis=fa)\n",
    "        masks = np.mean(masks_tta, axis=0, keepdims=True)\n",
    "        aux_mask = np.mean(auxseg_tta, axis=0, keepdims=True)\n",
    "        aux_prob = np.max(aux_mask, axis=(1,2))[0,:-1]\n",
    "        cls_prob = np.mean(cls_tta, axis=0)\n",
    "        \n",
    "        nbr = nbr_df['nonBlackRegion'].iloc[gi]\n",
    "        filename = nbr_df['ImageId'].iloc[gi]\n",
    "        image_df = input_df[input_df['ImageId'] == filename].copy()\n",
    "        \n",
    "        cls_classes = cls_prob > cls_th\n",
    "        aux_classes = aux_prob > aux_th\n",
    "        if not use_masks_from_df:\n",
    "            pred_masks = np.zeros((256,1600,4))\n",
    "            pred_masks[:, nbr[0]:nbr[1], :] = argmax_predictions(masks)[..., :-1]\n",
    "            pred_rles = build_rles(np.squeeze(pred_masks))\n",
    "        else:\n",
    "            pred_rles = image_df['EncodedPixels'].values\n",
    "        filtered_rles = [rle if c and a else '' for rle, c, a, in zip(pred_rles, cls_classes, aux_classes)]\n",
    "        if use_masks_from_df:\n",
    "            pred_masks = np.zeros((256,1600,4))\n",
    "            pred_masks[:, nbr[0]:nbr[1], :] = argmax_predictions(masks)[..., :-1]\n",
    "            pred_rles_new = build_rles(np.squeeze(pred_masks))\n",
    "            if cls_classes[1] and aux_classes[1]:\n",
    "                filtered_rles[1] = pred_rles_new[1]\n",
    "        image_df['EncodedPixels'] = filtered_rles\n",
    "        \n",
    "        res_df.append(image_df)\n",
    "#         if gi == 3:\n",
    "#             break\n",
    "        if gi % 100 == 0:\n",
    "            print(gi, \"Time elapsed %fs\"%(time.time()-tic))\n",
    "    print(\"Time elapsed %fs\"%(time.time()-tic))\n",
    "    res_df = pd.concat(res_df)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Time elapsed 5.699108s\n",
      "100 Time elapsed 58.514515s\n",
      "200 Time elapsed 91.670245s\n",
      "300 Time elapsed 123.289593s\n",
      "400 Time elapsed 152.503062s\n",
      "500 Time elapsed 180.597569s\n",
      "600 Time elapsed 211.593437s\n",
      "700 Time elapsed 238.902205s\n",
      "800 Time elapsed 267.077644s\n",
      "900 Time elapsed 295.597157s\n",
      "1000 Time elapsed 322.376464s\n",
      "1100 Time elapsed 350.554846s\n",
      "1200 Time elapsed 376.835001s\n",
      "1300 Time elapsed 403.319120s\n",
      "1400 Time elapsed 430.125485s\n",
      "1500 Time elapsed 459.699182s\n",
      "1600 Time elapsed 489.432456s\n",
      "1700 Time elapsed 516.812775s\n",
      "1800 Time elapsed 544.735178s\n",
      "Time elapsed 544.735404s\n",
      "0 Time elapsed 0.105656s\n",
      "100 Time elapsed 28.642224s\n",
      "200 Time elapsed 54.685401s\n",
      "300 Time elapsed 82.271024s\n",
      "400 Time elapsed 108.371836s\n",
      "500 Time elapsed 135.814218s\n",
      "600 Time elapsed 165.344424s\n",
      "700 Time elapsed 192.130623s\n",
      "800 Time elapsed 219.709339s\n",
      "900 Time elapsed 247.966470s\n",
      "1000 Time elapsed 274.829532s\n",
      "1100 Time elapsed 303.363520s\n",
      "1200 Time elapsed 329.144577s\n",
      "1300 Time elapsed 355.337458s\n",
      "1400 Time elapsed 381.600029s\n",
      "1500 Time elapsed 410.178683s\n",
      "1600 Time elapsed 439.720137s\n",
      "1700 Time elapsed 466.955402s\n",
      "1800 Time elapsed 494.609317s\n",
      "Time elapsed 494.609509s\n"
     ]
    }
   ],
   "source": [
    "aux_thresh = [0.99, 0.7, 0.9, 0.8]\n",
    "cls_thresh = [0.5, 0.5, 0.5, 0.4]\n",
    "model.load_weights(modelnamefold1)\n",
    "test_res_df = get_predictions(test_generator, nbr_df, sample_df, cls_thresh, aux_thresh, use_masks_from_df=False)\n",
    "\n",
    "aux_thresh = [0.2, 0.7, 0.7, 0.7]\n",
    "cls_thresh = [0.2, 0.9, 0.8, 0.8]\n",
    "model.load_weights(modelnamefold2)\n",
    "test_res_df = get_predictions(test_generator, nbr_df, test_res_df.copy(), cls_thresh, aux_thresh, use_masks_from_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sub_csv(df, csvname):\n",
    "    sub_result_df= pd.DataFrame(df['ImageId_ClassId'])\n",
    "    sub_result_df['EncodedPixels'] = df['EncodedPixels']\n",
    "    sub_result_df.to_csv(csvname, index=False)\n",
    "save_sub_csv(test_res_df.copy(), 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
