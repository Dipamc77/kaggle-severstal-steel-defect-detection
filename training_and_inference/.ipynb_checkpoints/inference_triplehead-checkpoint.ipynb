{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, keras, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from unet import Unet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)\n",
    "#keras.backend.set_session(sess)\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "modelname = '../models/efub4_nbr320_tripleloss_combosegdense.h5'\n",
    "aux_thresh = [0.99, 0.95, 0.7, 0.8]\n",
    "cls_thresh = [0.5, 0.5, 0.4, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFlip(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, x):\n",
    "        return tf.image.flip_left_right(x)\n",
    "    \n",
    "class VFlip(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, x):\n",
    "        return tf.image.flip_up_down(x)\n",
    "    \n",
    "class Rot180(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, x):\n",
    "        return tf.image.flip_left_right(x)\n",
    "    \n",
    "class Gray2RGB(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, x):\n",
    "        return tf.image.grayscale_to_rgb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "SEED=2019\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataGenerator():\n",
    "    def __init__(self ,image_folder, df=None, mean_std = (0., 1.)):\n",
    "        self.df = df\n",
    "        self.image_folder = image_folder\n",
    "        self.mean_std = mean_std\n",
    "        self.use_nbr = 'nonBlackRegion' in df.columns\n",
    "        self.lendf = len(df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.lendf\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        im_name = self.df['ImageId'].iloc[index]\n",
    "        img_path = self.image_folder + im_name\n",
    "        img = self._load_rgb(img_path)\n",
    "        if self.use_nbr is not None:\n",
    "            nbr = self.df['nonBlackRegion'].iloc[index]\n",
    "            img = img[:,nbr[0]:nbr[1],:]\n",
    "        img_tta = np.empty((4, *img.shape))\n",
    "        img_tta[0] = img\n",
    "        for ti, fa in enumerate([0, 1, (0,1)]):\n",
    "            img_tta[ti+1] = np.flip(img, axis=fa)\n",
    "        return img_tta\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def _load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path, 0)[..., None]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = (img - self.mean_std[0]) / self.mean_std[1]\n",
    "        return img\n",
    "    \n",
    "def mask2rle(img):\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.tenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    return rles\n",
    "\n",
    "def findNonBlackRegion(img):\n",
    "    assert len(img.shape) == 2\n",
    "    thd = img < 20\n",
    "    vert = np.int32(np.all(thd, axis=0))\n",
    "    vertshift = vert[:-1] - vert[1:]\n",
    "    if vert[0] == 1: # left side\n",
    "        maxind = img.shape[-1]\n",
    "        minind = np.min(np.where(vertshift==1))\n",
    "        return [minind, maxind], True\n",
    "    elif vert[-1] == 1: # right side\n",
    "        minind = 0\n",
    "        maxind = np.max(np.where(vertshift==-1)) + 1\n",
    "        return [minind, maxind], True\n",
    "    else:\n",
    "        return [0, img.shape[-1]], False\n",
    "    \n",
    "def nonBlackRegion(imgname, folder, roundoff=None):\n",
    "    img = cv2.imread(folder + imgname, 0)\n",
    "    nbr, _ = findNonBlackRegion(img)\n",
    "    if roundoff is not None:\n",
    "        diff = (nbr[0] - nbr[1])\n",
    "        if nbr[0] == 0:\n",
    "            nbr[1] = nbr[1] + (diff % roundoff)\n",
    "        else:\n",
    "            nbr[0] = nbr[0] - (diff % roundoff)\n",
    "#     assert nbr[0] >= 0, \"%s\"%(str(nbr))\n",
    "#     assert nbr[1] <= 1600, \"%s\"%(str(nbr))\n",
    "#     assert (nbr[1] - nbr[0]) % 32 == 0, \"%s\"%(str(nbr))\n",
    "    return nbr\n",
    "\n",
    "def argmax_predictions(predictions):\n",
    "    predflat = np.reshape(predictions, (-1, predictions.shape[-1]))\n",
    "    p_am = np.argmax(predflat, axis=-1)\n",
    "    outs = np.zeros(predflat.shape)\n",
    "    outs[np.arange(p_am.size), p_am] = 1\n",
    "    outs = np.reshape(outs, predictions.shape)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticstart = time.time()\n",
    "\n",
    "base_path = '../data/'\n",
    "images_folder = base_path + 'test_images/'\n",
    "sample_df = pd.read_csv(base_path+'sample_submission.csv')\n",
    "sample_df['ImageId'] = sample_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "nbr_df =  pd.DataFrame(sample_df['ImageId'].unique(), columns=['ImageId'])\n",
    "nbr_df['nonBlackRegion'] = nbr_df['ImageId'].apply(lambda name: nonBlackRegion(name, images_folder, 32))\n",
    "\n",
    "print(\"%fs\" % (time.time() - ticstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_std = (0.39531398, 0.1560004)  # without black regions\n",
    "test_generator = InferenceDataGenerator(image_folder = images_folder, df = nbr_df, mean_std = train_mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticstart = time.time()\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Conv2D, Concatenate, MaxPooling2D, Input\n",
    "# def get_model():\n",
    "BACKBONE = 'efficientnetb4'\n",
    "decoder_filters=(256, 128, 128, 64, 64)\n",
    "decoder_block_type = 'transpose3layer'\n",
    "auxseg_layername = 'decoder_stage4b2_swish' # changes with activation name\n",
    "layer_names = {'segmentation': 'masks', \n",
    "               'classification': 'classifier', \n",
    "               'auxilliary': 'auxilliary_segmentation'}\n",
    "effunet = Unet(backbone_name = BACKBONE, input_shape=(None,None,3), \n",
    "                 encoder_weights=None, \n",
    "                 encoder_freeze=False, \n",
    "                 classes=5,\n",
    "                 activation='softmax',\n",
    "                 decoder_filters=decoder_filters,\n",
    "                 output_name=layer_names['segmentation'], \n",
    "                 decoder_activation='swish',\n",
    "                 decoder_block_type = decoder_block_type)\n",
    "\n",
    "\n",
    "\n",
    "seghead = neweffunet.layers[-1].get_layer(auxseg_layername).output\n",
    "auxseg = Conv2D(filters=5, kernel_size=(3, 3), \n",
    "                padding='same', use_bias=True,\n",
    "                activation='softmax',\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                name=layer_names['auxilliary'])(seghead)\n",
    "\n",
    "x = MaxPooling2D(32)(auxseg)\n",
    "poolseg = GlobalAveragePooling2D()(x)\n",
    "avgseg = GlobalAveragePooling2D()(auxseg)\n",
    "maxseg = GlobalMaxPooling2D()(auxseg)\n",
    "x = Concatenate()([maxseg, avgseg, poolseg])\n",
    "classifier = Dense(4, activation='sigmoid', name=layer_names['classification'])(x)  \n",
    "\n",
    "oldmodel = Model(inputs=effunet.inputs, outputs=[effunet.output, classifier, auxseg])\n",
    "oldmodel.load_weights(modelname)\n",
    "\n",
    "#     testflip = HFlip()(effunet.output)\n",
    "#     model = Model(inputs=effunet.inputs, outputs=[testflip, classifier, auxseg])\n",
    "newinp = Input(shape=(None, None, 1))\n",
    "rgbimg = Gray2RGB()(newinp)\n",
    "attach = effunet(rgbimg)\n",
    "neweffunet = Model(inputs=newinp, outputs=attach)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model = get_model()\n",
    "\n",
    "print(\"%fs\" % (time.time() - ticstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(inference_generator, nbr_df, input_df, cls_thresh, aux_thresh):\n",
    "    tic = time.time()\n",
    "    res_df = []\n",
    "    for gi in range(len(inference_generator)):\n",
    "        tta_img = inference_generator[gi]\n",
    "        modelout_tta = model.predict_on_batch(tta_img)\n",
    "        masks_tta, cls_tta, auxseg_tta = modelout_tta\n",
    "        for ti, fa in enumerate([0, 1, (0,1)]):\n",
    "            masks_tta[ti+1] = np.flip(masks_tta[ti+1], axis=fa)\n",
    "            auxseg_tta[ti+1] = np.flip(auxseg_tta[ti+1], axis=fa)\n",
    "        masks = np.mean(masks_tta, axis=0, keepdims=True)\n",
    "        aux_mask = np.mean(auxseg_tta, axis=0, keepdims=True)\n",
    "        aux_prob = np.max(aux_mask, axis=(1,2))[0,:-1]\n",
    "        cls_prob = np.mean(cls_tta, axis=0)\n",
    "        \n",
    "        nbr = nbr_df['nonBlackRegion'].iloc[gi]\n",
    "        filename = nbr_df['ImageId'].iloc[gi]\n",
    "        image_df = input_df[input_df['ImageId'] == filename].copy()\n",
    "        \n",
    "        pred_masks = np.zeros((256,1600,4))\n",
    "        pred_masks[:, nbr[0]:nbr[1], :] = argmax_predictions(masks)[..., :-1]\n",
    "        pred_rles = build_rles(np.squeeze(pred_masks))\n",
    "        \n",
    "        cls_classes = cls_prob > cls_thresh\n",
    "        aux_classes = aux_prob > aux_thresh\n",
    "        filtered_rles = [rle if c and a else '' for rle, c, a, in zip(pred_rles, cls_classes, aux_classes)]\n",
    "        image_df['EncodedPixels'] = filtered_rles\n",
    "        \n",
    "        res_df.append(image_df)\n",
    "#         if gi == 3:\n",
    "#             break\n",
    "        if gi % 500 == 0:\n",
    "            print(gi, \"Time elapsed %fs\"%(time.time()-tic))\n",
    "    print(\"Time elapsed %fs\"%(time.time()-tic))\n",
    "    res_df = pd.concat(res_df)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_df = get_predictions(test_generator, nbr_df, sample_df, cls_thresh, aux_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sub_csv(df, csvname):\n",
    "    sub_result_df= pd.DataFrame(df['ImageId_ClassId'])\n",
    "    sub_result_df['EncodedPixels'] = df['EncodedPixels']\n",
    "    sub_result_df.to_csv(csvname, index=False)\n",
    "save_sub_csv(test_res_df.copy(), 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldmsk = oldmodelout_tta[0]\n",
    "plt.imshow(oldmsk[1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oldmsk.npy', oldmsk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
